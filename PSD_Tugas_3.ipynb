{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "f24149ee-2aa4-4f69-9cbc-6eaf1c301f0c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Konfigurasi tampilan\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Library berhasil diimpor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3",
    "outputId": "c551abd8-ef55-4da0-a0e9-5df5dbfc6481"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('https://github.com/erlanggadewasakti/Prinsip-Sains-Data/releases/download/prod/sa-psd-dataset.csv')\n",
    "    print(f\"Dataset berhasil dimuat: {len(df)} baris, {len(df.columns)} kolom\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "## 3. Inspeksi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "5",
    "outputId": "fcb5f55b-09a5-4867-8a7a-d93668f0872b"
   },
   "outputs": [],
   "source": [
    "print(\"Sample Data:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nInfo Dataset:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nStatistik Deskriptif:\")\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "source": [
    "## 4. Identifikasi Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "7",
    "outputId": "6c60ab31-1be3-47ee-e589-8f7ac7caf028"
   },
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Kolom': missing_values.index,\n",
    "    'Jumlah Missing': missing_values.values,\n",
    "    'Persentase (%)': missing_percentage.values\n",
    "})\n",
    "\n",
    "print(\"Analisis Missing Values:\")\n",
    "print(missing_df[missing_df['Jumlah Missing'] > 0])\n",
    "\n",
    "if missing_df['Jumlah Missing'].sum() == 0:\n",
    "    print(\"\\nTidak ada missing values.\")\n",
    "else:\n",
    "    print(f\"\\nTotal missing: {missing_df['Jumlah Missing'].sum()}\")\n",
    "\n",
    "    # Visualisasi jika ada missing values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    missing_cols = missing_df[missing_df['Jumlah Missing'] > 0]\n",
    "    plt.barh(missing_cols['Kolom'], missing_cols['Persentase (%)'])\n",
    "    plt.xlabel('Persentase Missing (%)')\n",
    "    plt.title('Distribusi Missing Values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8",
    "outputId": "2fd8cb4f-cba5-48b7-dde8-90260cf630a0"
   },
   "outputs": [],
   "source": [
    "# Strategi: Drop baris dengan missing values pada kolom input/output\n",
    "df_clean = df.copy()\n",
    "\n",
    "if df_clean.isnull().sum().sum() > 0:\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.dropna(subset=['input', 'output'], how='any')\n",
    "    dropped_rows = initial_rows - len(df_clean)\n",
    "    print(f\"Baris dihapus: {dropped_rows}\")\n",
    "    print(f\"Sisa data: {len(df_clean)} baris\")\n",
    "else:\n",
    "    print(\"Tidak ada missing values.\")\n",
    "\n",
    "print(f\"\\nVerifikasi - Missing values: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "9"
   },
   "source": [
    "## 5. Identifikasi Data Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "10",
    "outputId": "a599e4a8-9704-416c-89dc-afa682befec7"
   },
   "outputs": [],
   "source": [
    "duplicates_all = df_clean.duplicated().sum()\n",
    "duplicates_input = df_clean.duplicated(subset=['input']).sum()\n",
    "\n",
    "print(f\"Duplikat (semua kolom): {duplicates_all}\")\n",
    "print(f\"Duplikat (kolom input): {duplicates_input}\")\n",
    "\n",
    "if duplicates_input > 0:\n",
    "    print(\"\\nContoh data duplikat:\")\n",
    "    duplicate_samples = df_clean[df_clean.duplicated(subset=['input'], keep=False)].sort_values('input').head(10)\n",
    "    display(duplicate_samples[['input', 'output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11",
    "outputId": "660c8061-c838-4838-abdd-c00d86d15b1c"
   },
   "outputs": [],
   "source": [
    "initial_rows = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['input'], keep='first')\n",
    "removed_duplicates = initial_rows - len(df_clean)\n",
    "\n",
    "print(f\"Duplikat dihapus: {removed_duplicates}\")\n",
    "print(f\"Total data: {len(df_clean)} baris\")\n",
    "\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "print(\"Index direset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "12"
   },
   "source": [
    "## 6. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13",
    "outputId": "65557e55-d29f-4769-8ac5-55d3aa99d53a"
   },
   "outputs": [],
   "source": [
    "def advanced_text_cleaning(text):\n",
    "    \"\"\"Membersihkan teks dari URL, HTML tags, karakter khusus, dan whitespace berlebihan\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return str(text) if text is not None else \"\"\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Hapus URL\n",
    "    text = re.sub(r'<.*?>', '', text)  # Hapus HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Hapus karakter khusus\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalisasi whitespace\n",
    "\n",
    "    return text\n",
    "\n",
    "df_clean['cleaned_input'] = df_clean['input'].apply(advanced_text_cleaning)\n",
    "\n",
    "print(\"Perbandingan Teks:\")\n",
    "for idx, row in df_clean[['input', 'cleaned_input']].head(3).iterrows():\n",
    "    print(f\"\\n[{idx + 1}] Original : {row['input'][:100]}...\")\n",
    "    print(f\"    Cleaned  : {row['cleaned_input'][:100]}...\")\n",
    "\n",
    "print(f\"\\nText cleaning selesai untuk {len(df_clean)} baris.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "14"
   },
   "source": [
    "## 7. Ekstraksi dan Normalisasi Label Sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "15",
    "outputId": "f6307d6d-5494-4ff5-ea6c-bb6acad98471"
   },
   "outputs": [],
   "source": [
    "# Ekstraksi label dari kolom output\n",
    "df_clean['sentiment'] = df_clean['output'].str.replace(r'^[A-E]:\\s*', '', regex=True)\n",
    "\n",
    "print(\"Distribusi Sebelum Normalisasi:\")\n",
    "print(df_clean['sentiment'].value_counts())\n",
    "\n",
    "# Normalisasi: gabungkan very positive/negative dengan positive/negative\n",
    "sentiment_normalization = {\n",
    "    'very positive': 'positive',\n",
    "    'very negative': 'negative',\n",
    "    'positive': 'positive',\n",
    "    'negative': 'negative',\n",
    "    'neutral': 'neutral'\n",
    "}\n",
    "\n",
    "df_clean['sentiment'] = df_clean['sentiment'].map(sentiment_normalization)\n",
    "\n",
    "print(\"\\nDistribusi Setelah Normalisasi:\")\n",
    "print(df_clean['sentiment'].value_counts())\n",
    "print(\"\\nProporsi:\")\n",
    "print(df_clean['sentiment'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSample Hasil:\")\n",
    "display(df_clean[['output', 'sentiment', 'cleaned_input']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "source": [
    "## 8. Visualisasi Distribusi Sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "17",
    "outputId": "67b85746-25a4-4aa9-c10f-9259f7c31143"
   },
   "outputs": [],
   "source": [
    "sentiment_colors = {'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#3498db'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(x='sentiment', data=df_clean, hue='sentiment', palette=sentiment_colors, legend=False, ax=axes[0])\n",
    "axes[0].set_title('Distribusi Sentimen', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Kategori')\n",
    "axes[0].set_ylabel('Jumlah')\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%d')\n",
    "\n",
    "# Pie chart\n",
    "sentiment_counts = df_clean['sentiment'].value_counts()\n",
    "colors = [sentiment_colors[label] for label in sentiment_counts.index]\n",
    "axes[1].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90)\n",
    "axes[1].set_title('Proporsi Sentimen', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisis imbalance\n",
    "majority_class = sentiment_counts.idxmax()\n",
    "minority_class = sentiment_counts.idxmin()\n",
    "imbalance_ratio = sentiment_counts.max() / sentiment_counts.min()\n",
    "\n",
    "print(f\"Mayoritas: {majority_class} ({sentiment_counts.max()} data)\")\n",
    "print(f\"Minoritas: {minority_class} ({sentiment_counts.min()} data)\")\n",
    "print(f\"Rasio imbalance: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"âš ï¸  Dataset imbalanced - perlu oversampling!\")\n",
    "else:\n",
    "    print(\"âœ“ Dataset relatif seimbang.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "18"
   },
   "source": [
    "## 9. Encoding Label Sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "19",
    "outputId": "02df50a0-fc1a-4697-dbe2-5c5b211245da"
   },
   "outputs": [],
   "source": [
    "sentiment_mapping = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "df_clean['sentiment_encoded'] = df_clean['sentiment'].map(sentiment_mapping)\n",
    "\n",
    "print(\"Mapping Sentimen:\")\n",
    "for sentiment, code in sentiment_mapping.items():\n",
    "    count = (df_clean['sentiment_encoded'] == code).sum()\n",
    "    print(f\"{sentiment:10s} -> {code} ({count:6d} data)\")\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "display(df_clean[['cleaned_input', 'sentiment', 'sentiment_encoded']].head(5))\n",
    "\n",
    "assert df_clean['sentiment_encoded'].isnull().sum() == 0, \"Ada nilai yang tidak termap!\"\n",
    "print(\"\\nâœ“ Encoding berhasil.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "## 10. Analisis Panjang Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "21",
    "outputId": "2068a1ff-d5e8-4799-e4dc-94962dbd624b"
   },
   "outputs": [],
   "source": [
    "df_clean['text_length_chars'] = df_clean['cleaned_input'].str.len()\n",
    "df_clean['text_length_words'] = df_clean['cleaned_input'].str.split().str.len()\n",
    "\n",
    "print(\"Statistik Panjang (Karakter):\")\n",
    "print(df_clean['text_length_chars'].describe())\n",
    "\n",
    "print(\"\\nStatistik Panjang (Kata):\")\n",
    "print(df_clean['text_length_words'].describe())\n",
    "\n",
    "# Visualisasi\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(df_clean['text_length_chars'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df_clean['text_length_chars'].median(), color='red', linestyle='--',\n",
    "                label=f\"Median: {df_clean['text_length_chars'].median():.0f}\")\n",
    "axes[0].set_xlabel('Jumlah Karakter')\n",
    "axes[0].set_ylabel('Frekuensi')\n",
    "axes[0].set_title('Distribusi Panjang Teks (Karakter)', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(df_clean['text_length_words'], bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(df_clean['text_length_words'].median(), color='blue', linestyle='--',\n",
    "                label=f\"Median: {df_clean['text_length_words'].median():.0f}\")\n",
    "axes[1].set_xlabel('Jumlah Kata')\n",
    "axes[1].set_ylabel('Frekuensi')\n",
    "axes[1].set_title('Distribusi Panjang Teks (Kata)', fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "22"
   },
   "source": [
    "## 11. Split Data (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23",
    "outputId": "55ccee47-25a8-4629-803d-d2dce0dc2632"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split training (70%) dan temporary (30%)\n",
    "df_train, df_temp, _, _ = train_test_split(\n",
    "    df_clean, df_clean['sentiment_encoded'],\n",
    "    test_size=0.3, random_state=RANDOM_STATE, stratify=df_clean['sentiment_encoded']\n",
    ")\n",
    "\n",
    "# Split temporary menjadi validation (15%) dan testing (15%)\n",
    "df_val, df_test, _, _ = train_test_split(\n",
    "    df_temp, df_temp['sentiment_encoded'],\n",
    "    test_size=0.5, random_state=RANDOM_STATE, stratify=df_temp['sentiment_encoded']\n",
    ")\n",
    "\n",
    "print(f\"Training   : {len(df_train)} baris ({len(df_train)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Validation : {len(df_val)} baris ({len(df_val)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Testing    : {len(df_test)} baris ({len(df_test)/len(df_clean)*100:.1f}%)\")\n",
    "\n",
    "# Verifikasi stratifikasi\n",
    "print(\"\\nDistribusi Sentimen:\")\n",
    "print(\"Train     :\", df_train['sentiment'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Validation:\", df_val['sentiment'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Test      :\", df_test['sentiment'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"\\nâœ“ Stratifikasi berhasil.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "24"
   },
   "source": [
    "## 12. Oversampling Training Set\n",
    "\n",
    "**Catatan**: Oversampling hanya pada training set untuk mencegah data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25",
    "outputId": "076a47bf-61ed-4e24-d0f4-e605bfe58973"
   },
   "outputs": [],
   "source": [
    "majority_count = df_train['sentiment'].value_counts().max()\n",
    "\n",
    "print(f\"Target per kelas: {majority_count} samples\")\n",
    "print(\"\\nSebelum oversampling:\")\n",
    "print(df_train['sentiment'].value_counts().sort_index())\n",
    "\n",
    "df_train_oversampled = pd.DataFrame()\n",
    "\n",
    "for sentiment_label in df_train['sentiment'].unique():\n",
    "    sentiment_df = df_train[df_train['sentiment'] == sentiment_label]\n",
    "    current_count = len(sentiment_df)\n",
    "\n",
    "    if current_count < majority_count:\n",
    "        oversampled_df = sentiment_df.sample(n=majority_count, replace=True, random_state=RANDOM_STATE)\n",
    "        print(f\"{sentiment_label:10s}: {current_count:5d} -> {len(oversampled_df):5d} (oversampled)\")\n",
    "    else:\n",
    "        oversampled_df = sentiment_df\n",
    "        print(f\"{sentiment_label:10s}: {current_count:5d} (unchanged)\")\n",
    "\n",
    "    df_train_oversampled = pd.concat([df_train_oversampled, oversampled_df], ignore_index=True)\n",
    "\n",
    "# Shuffle data\n",
    "df_train_oversampled = df_train_oversampled.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nSetelah oversampling:\")\n",
    "print(df_train_oversampled['sentiment'].value_counts().sort_index())\n",
    "print(f\"\\nTotal: {len(df_train)} -> {len(df_train_oversampled)} baris (+{len(df_train_oversampled)-len(df_train)})\")\n",
    "print(\"âœ“ Oversampling selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "26"
   },
   "source": [
    "## 13. Visualisasi Perbandingan Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "27",
    "outputId": "e0adbba5-2e61-4efa-da24-27d4a9086e57"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Sebelum oversampling\n",
    "df_train['sentiment'].value_counts().sort_index().plot(\n",
    "    kind='bar', ax=axes[0], color=['#e74c3c', '#3498db', '#2ecc71'],\n",
    "    edgecolor='black', alpha=0.7\n",
    ")\n",
    "axes[0].set_title('SEBELUM Oversampling', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentimen')\n",
    "axes[0].set_ylabel('Jumlah')\n",
    "axes[0].set_xticklabels(['Negative', 'Neutral', 'Positive'], rotation=0)\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='%d')\n",
    "\n",
    "# Setelah oversampling\n",
    "df_train_oversampled['sentiment'].value_counts().sort_index().plot(\n",
    "    kind='bar', ax=axes[1], color=['#e74c3c', '#3498db', '#2ecc71'],\n",
    "    edgecolor='black', alpha=0.7\n",
    ")\n",
    "axes[1].set_title('SETELAH Oversampling', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Sentimen')\n",
    "axes[1].set_ylabel('Jumlah')\n",
    "axes[1].set_xticklabels(['Negative', 'Neutral', 'Positive'], rotation=0)\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%d')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "28"
   },
   "source": [
    "## 14. Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29",
    "outputId": "57f571fd-dac8-4243-e38a-933af67a14e6"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(f\"Tokenizer: bert-base-uncased\")\n",
    "print(f\"Vocab size: {tokenizer.vocab_size:,}\")\n",
    "print(f\"Max length: {tokenizer.model_max_length}\")\n",
    "print(\"âœ“ Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "30"
   },
   "source": [
    "## 15. Analisis Panjang Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "id": "31",
    "outputId": "ff6356bb-bbf6-46ef-9ed5-cd8a3e354531"
   },
   "outputs": [],
   "source": [
    "token_lengths = [\n",
    "    len(tokenizer.encode(str(text), add_special_tokens=True, truncation=True, max_length=512))\n",
    "    for text in df_train_oversampled['cleaned_input']\n",
    "]\n",
    "\n",
    "print(\"Statistik Panjang Token:\")\n",
    "print(f\"Min     : {np.min(token_lengths)}\")\n",
    "print(f\"Max     : {np.max(token_lengths)}\")\n",
    "print(f\"Mean    : {np.mean(token_lengths):.2f}\")\n",
    "print(f\"Median  : {np.median(token_lengths):.0f}\")\n",
    "print(f\"P95     : {np.percentile(token_lengths, 95):.0f}\")\n",
    "print(f\"P99     : {np.percentile(token_lengths, 99):.0f}\")\n",
    "\n",
    "# Visualisasi\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(token_lengths, bins=50, kde=True, color='steelblue', edgecolor='black', alpha=0.6)\n",
    "plt.axvline(np.mean(token_lengths), color='red', linestyle='--',\n",
    "            label=f'Mean: {np.mean(token_lengths):.0f}', linewidth=2)\n",
    "plt.axvline(np.percentile(token_lengths, 95), color='orange', linestyle='--',\n",
    "            label=f'P95: {np.percentile(token_lengths, 95):.0f}', linewidth=2)\n",
    "plt.xlabel('Jumlah Token')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.title('Distribusi Panjang Token', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tentukan MAX_LENGTH\n",
    "suggested = int(np.percentile(token_lengths, 95))\n",
    "MAX_LENGTH = min(suggested, 512)\n",
    "if MAX_LENGTH > 400:\n",
    "    MAX_LENGTH = 330  # Nilai praktis\n",
    "\n",
    "print(f\"\\nSuggested MAX_LENGTH: {suggested}\")\n",
    "print(f\"Chosen MAX_LENGTH: {MAX_LENGTH}\")\n",
    "print(f\"Coverage: {(np.array(token_lengths) <= MAX_LENGTH).sum() / len(token_lengths) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "32"
   },
   "source": [
    "## 16. Tokenisasi Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33",
    "outputId": "dfbdf610-e0b0-4558-afa5-f1cd7c310d14"
   },
   "outputs": [],
   "source": [
    "def tokenize_data(texts, tokenizer, max_length):\n",
    "    \"\"\"Tokenisasi teks dengan padding dan truncation\"\"\"\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenisasi semua dataset\n",
    "X_train_tokenized = tokenize_data(df_train_oversampled['cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "X_val_tokenized = tokenize_data(df_val['cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "X_test_tokenized = tokenize_data(df_test['cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"MAX_LENGTH: {MAX_LENGTH} tokens\\n\")\n",
    "print(f\"Training   : {X_train_tokenized['input_ids'].shape}\")\n",
    "print(f\"Validation : {X_val_tokenized['input_ids'].shape}\")\n",
    "print(f\"Testing    : {X_test_tokenized['input_ids'].shape}\")\n",
    "print(\"\\nâœ“ Tokenisasi selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "34"
   },
   "source": [
    "## 17. Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "35",
    "outputId": "a4c64cc3-c6b0-4e3c-fc63-ef4abb618067"
   },
   "outputs": [],
   "source": [
    "data_dict = pd.DataFrame({\n",
    "    'Kolom': ['input', 'output', 'cleaned_input', 'sentiment', 'sentiment_encoded', 'text_length_chars', 'text_length_words'],\n",
    "    'Tipe': ['string', 'string', 'string', 'string', 'int64', 'int64', 'int64'],\n",
    "    'Deskripsi': [\n",
    "        'Teks original dari dataset',\n",
    "        'Label output dengan format prefix (A:, B:, dst)',\n",
    "        'Teks yang sudah dibersihkan dari noise',\n",
    "        'Label sentimen kategorikal (positive/negative/neutral)',\n",
    "        'Label sentimen numerik (0: positive, 1: neutral, 2: negative)',\n",
    "        'Jumlah karakter teks bersih',\n",
    "        'Jumlah kata teks bersih'\n",
    "    ],\n",
    "    'Contoh': ['Amazing product!', 'A: very positive', 'Amazing product', 'positive', '0', '16', '2']\n",
    "})\n",
    "\n",
    "print(\"Data Dictionary:\")\n",
    "display(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "36"
   },
   "source": [
    "## 18. Summary Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37",
    "outputId": "afeab3e1-8a7c-4ef4-e7dd-745d1bf91405"
   },
   "outputs": [],
   "source": [
    "print(\"LAPORAN PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸ“Š Statistik Dataset:\")\n",
    "print(f\"  Original         : {len(df):,} baris\")\n",
    "print(f\"  Duplikat dihapus : {removed_duplicates:,} baris\")\n",
    "print(f\"  Data bersih      : {len(df_clean):,} baris\")\n",
    "\n",
    "print(\"\\nðŸ“‚ Data Split:\")\n",
    "print(f\"  Training (ori)   : {len(df_train):,} baris\")\n",
    "print(f\"  Training (over)  : {len(df_train_oversampled):,} baris\")\n",
    "print(f\"  Validation       : {len(df_val):,} baris\")\n",
    "print(f\"  Testing          : {len(df_test):,} baris\")\n",
    "\n",
    "print(\"\\nðŸ”„ Transformasi:\")\n",
    "print(f\"  Text cleaning    : âœ“\")\n",
    "print(f\"  Label encoding   : âœ“ (3 kelas)\")\n",
    "print(f\"  Oversampling     : âœ“ (ratio 1:1:1)\")\n",
    "print(f\"  Tokenization     : âœ“ (BERT, max_length={MAX_LENGTH})\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Distribusi Sentimen (Training Oversampled):\")\n",
    "for sent in ['negative', 'neutral', 'positive']:\n",
    "    count = (df_train_oversampled['sentiment'] == sent).sum()\n",
    "    pct = count / len(df_train_oversampled) * 100\n",
    "    print(f\"  {sent.capitalize():10s}: {count:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ PREPROCESSING SELESAI - DATASET SIAP\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "38"
   },
   "source": [
    "## 19. Ekspor Dataset (Opsional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39",
    "outputId": "360fe951-e618-4367-b031-145795fe7720"
   },
   "outputs": [],
   "source": [
    "output_file = 'sentiment_dataset_cleaned.csv'\n",
    "\n",
    "columns_to_save = ['input', 'output', 'cleaned_input', 'sentiment', 'sentiment_encoded', 'text_length_chars', 'text_length_words']\n",
    "\n",
    "df_clean[columns_to_save].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ“ Dataset saved: {output_file}\")\n",
    "print(f\"  Rows: {len(df_clean):,}\")\n",
    "print(f\"  Cols: {len(columns_to_save)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "40",
    "outputId": "ae7fdce5-ba39-43ee-d348-25308bfe2326"
   },
   "outputs": [],
   "source": [
    "# Konversi tokenized data ke PyTorch tensors\n",
    "input_ids_train = X_train_tokenized['input_ids']\n",
    "attention_mask_train = X_train_tokenized['attention_mask']\n",
    "token_type_ids_train = X_train_tokenized['token_type_ids']\n",
    "labels_train = torch.tensor(df_train_oversampled['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "input_ids_val = X_val_tokenized['input_ids']\n",
    "attention_mask_val = X_val_tokenized['attention_mask']\n",
    "token_type_ids_val = X_val_tokenized['token_type_ids']\n",
    "labels_val = torch.tensor(df_val['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "input_ids_test = X_test_tokenized['input_ids']\n",
    "attention_mask_test = X_test_tokenized['attention_mask']\n",
    "token_type_ids_test = X_test_tokenized['token_type_ids']\n",
    "labels_test = torch.tensor(df_test['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "# Buat TensorDataset\n",
    "train_dataset = TensorDataset(input_ids_train, attention_mask_train, token_type_ids_train, labels_train)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_mask_val, token_type_ids_val, labels_val)\n",
    "test_dataset = TensorDataset(input_ids_test, attention_mask_test, token_type_ids_test, labels_test)\n",
    "\n",
    "# Buat DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\\n\")\n",
    "print(f\"Train batches : {len(train_dataloader)}\")\n",
    "print(f\"Val batches   : {len(val_dataloader)}\")\n",
    "print(f\"Test batches  : {len(test_dataloader)}\")\n",
    "print(\"\\nâœ“ DataLoader siap untuk training.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
