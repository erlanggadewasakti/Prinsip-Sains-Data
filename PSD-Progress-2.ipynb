{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d4fbc34"
   },
   "source": [
    "# Task - PREPARE DATASET\n",
    "Mount Google Drive, load the CSV file \"/content/drive/MyDrive/Colab Notebooks/sentiment-analysis-training-data.csv\" into a pandas DataFrame, and display the first few rows of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5730d4f3"
   },
   "source": [
    "## Mount Google Drive\n",
    "\n",
    "Hubungkan Google Drive ke sesi Colab saat ini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0762d724"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "023037bc"
   },
   "source": [
    "## Load CSV File\n",
    "\n",
    "Muat file CSV dari path yang ditentukan ke dalam pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a15d9c1",
    "outputId": "fffaca9c-11d3-4d60-cb9c-b3f812140343"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv('https://github.com/erlanggadewasakti/Prinsip-Sains-Data/releases/download/prod/sa-psd-dataset.csv')\n",
    "    print(\"Dataset berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File dataset tidak ditemukan. Pastikan path file sudah benar.\")\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error saat membaca file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIi3E1D5Nefq"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a328e4f1"
   },
   "source": [
    "# Task - EDA\n",
    "Perform a comprehensive sentiment analysis EDA on the \"ecinstruct-sentiment-analysis-samples.csv\" dataset, focusing on visualizations and insights. The analysis should include data loading and inspection, data preprocessing (extracting sentiment labels and cleaning input text), target distribution analysis (sentiment countplot), text statistics analysis (character length, word count, average word length with histograms and boxplots), content analysis (N-grams with bar plots), visual analysis (word clouds for all text and per sentiment category), and a summary of key insights. Use the required libraries: pandas, matplotlib.pyplot, seaborn, nltk, and wordcloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68080d95"
   },
   "source": [
    "## Muat & Inspeksi Data\n",
    "\n",
    "Muat data dari file CSV dan tampilkan informasi dasar seperti tipe data, beberapa baris pertama, dan jumlah nilai yang hilang.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "62405a62",
    "outputId": "4cabac82-1b9a-4a02-ab13-9719c0a4724e"
   },
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "df.info()\n",
    "print(\"\\nJumlah nilai yang hilang per kolom:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4129bfe1"
   },
   "source": [
    "## Pra-pemrosesan Data\n",
    "\n",
    "Buat kolom baru untuk label sentimen yang bersih dan teks input yang sudah dibersihkan (lowercase, tanpa tanda baca, tanpa angka).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e71baf2",
    "outputId": "b509de1a-ee8f-47bb-b20d-69c2665011fc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract sentiment labels\n",
    "df['sentiment'] = df['output'].str.replace(r'^[A-E]:\\s*', '', regex=True)\n",
    "\n",
    "# Clean the input text\n",
    "df['cleaned_input'] = df['input'].str.lower()\n",
    "# df['cleaned_input'] = df['cleaned_input'].str.replace(r'[^\\w\\s]', '', regex=True) # Remove punctuation\n",
    "# df['cleaned_input'] = df['cleaned_input'].str.replace(r'\\d+', '', regex=True) # Remove numbers\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map({'very positive' : 'positive', 'very negative' : 'negative','positive':'positive','negative':'negative','neutral':'neutral'})\n",
    "\n",
    "# Display the first few rows with new columns\n",
    "display(df[['output', 'sentiment', 'input', 'cleaned_input']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9471778b"
   },
   "source": [
    "## Analisis Distribusi Sentimen\n",
    "\n",
    "Visualisasikan distribusi sentimen menggunakan diagram batang dan laporkan ketidakseimbangan data jika ada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c87f9685",
    "outputId": "61ee18f1-280c-4bcc-b608-87fdf21c7674"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentiment_colors = {'positive': 'green', 'negative': 'orange', 'neutral': 'blue'}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='sentiment', data=df, hue='sentiment', palette=sentiment_colors, legend=False)\n",
    "\n",
    "# Tambahkan keterangan angka di atas setiap bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0ae0be3"
   },
   "source": [
    "## Analisis Statistik Teks\n",
    "\n",
    "Hitung panjang karakter, jumlah kata, dan rata-rata panjang kata untuk setiap ulasan. Visualisasikan distribusi statistik teks ini menggunakan histogram dan boxplot berdasarkan sentimen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9f7cc6bf",
    "outputId": "4251cef3-5a5f-4c88-8d51-2976c1cb438d"
   },
   "outputs": [],
   "source": [
    "df['char_length'] = df['cleaned_input'].str.len()\n",
    "df['word_count'] = df['cleaned_input'].str.split().str.len()\n",
    "df['avg_word_length'] = df['char_length'] / df['word_count']\n",
    "df['avg_word_length'] = df['avg_word_length'].fillna(0) # Handle division by zero for empty strings\n",
    "\n",
    "display(df[['cleaned_input', 'char_length', 'word_count', 'avg_word_length']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "478bb94f",
    "outputId": "8de15cb4-dd6e-434d-d815-539a0c312f28"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histograms for text statistics by sentiment\n",
    "text_stats = ['char_length', 'word_count', 'avg_word_length']\n",
    "for stat in text_stats:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=df, x=stat, hue='sentiment', kde=True, multiple='stack', palette=sentiment_colors)\n",
    "    plt.title(f'Distribution of {stat} by Sentiment')\n",
    "    plt.xlabel(stat)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3704e76d",
    "outputId": "2ab26c0f-4f6d-4b32-bade-0d03e3d12e55"
   },
   "outputs": [],
   "source": [
    "# Boxplots for text statistics by sentiment\n",
    "text_stats = ['char_length', 'word_count', 'avg_word_length']\n",
    "for stat in text_stats:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='sentiment', y=stat,palette=sentiment_colors)\n",
    "    plt.title(f'Distribution of {stat} by Sentiment')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel(stat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e078929"
   },
   "source": [
    "## Analisis Konten (N-grams)\n",
    "\n",
    "Hapus stopwords dan hitung frekuensi unigram, bigram, dan trigram dari teks yang sudah dibersihkan. Visualisasikan 20 n-gram teratas untuk setiap kategori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71513ef4",
    "outputId": "3d9acb39-50d4-4b53-ad27-69e9eea56d36"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    stopwords_english = stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "print(\"Libraries imported and stopwords downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qN_rlv3G8tQq",
    "outputId": "3a0d171a-dfd1-45ac-c0f6-64770abb4613"
   },
   "outputs": [],
   "source": [
    "ngram_ranges = [(1, 1), (2, 2), (3, 3)]\n",
    "sentiments = df['sentiment'].unique()\n",
    "\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    print(f\"Analyzing sentiment: {sentiment}\")\n",
    "    sentiment_df = df[df['sentiment'] == sentiment]\n",
    "    cleaned_text = sentiment_df['cleaned_input'].dropna() # Drop NaN values\n",
    "\n",
    "    if cleaned_text.empty:\n",
    "        print(f\"No cleaned text available for sentiment: {sentiment}\")\n",
    "        continue\n",
    "\n",
    "    current_sentiment_color = sentiment_colors.get(sentiment, 'gray') # Default to gray if sentiment not found\n",
    "\n",
    "    for n_range in ngram_ranges:\n",
    "        print(f\"  Analyzing {n_range}-grams\")\n",
    "        vectorizer = CountVectorizer(ngram_range=n_range, stop_words=stopwords_english)\n",
    "        try:\n",
    "            X = vectorizer.fit_transform(cleaned_text)\n",
    "        except ValueError as e:\n",
    "            print(f\"  Could not fit vectorizer for {n_range}-grams and sentiment {sentiment}: {e}\")\n",
    "            continue\n",
    "\n",
    "        sum_words = X.sum(axis=0)\n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "        top_ngrams = words_freq[:20]\n",
    "\n",
    "        if not top_ngrams:\n",
    "            print(f\"  No {n_range}-grams found for sentiment: {sentiment}\")\n",
    "            continue\n",
    "\n",
    "        top_ngrams_df = pd.DataFrame(top_ngrams, columns=['ngram', 'count'])\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='count', y='ngram', data=top_ngrams_df, color=current_sentiment_color)\n",
    "        plt.title(f'Top 20 {n_range}-grams for Sentiment: {sentiment}')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel(f'{n_range}-gram')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"N-gram analysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6865d534"
   },
   "source": [
    "## Analisis Visual (Word Clouds)\n",
    "\n",
    "Buat word cloud dari semua teks yang sudah dibersihkan dan word cloud terpisah untuk setiap kategori sentimen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "112e6497",
    "outputId": "576bee5d-a87e-4955-9099-d0590db6aed9"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "try:\n",
    "    stopwords_english = stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "\n",
    "# Word cloud for all cleaned text\n",
    "all_text = ' '.join(df['cleaned_input'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords_english).generate(all_text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of All Text (excluding stopwords)')\n",
    "plt.show()\n",
    "\n",
    "# Identify overall most common words (excluding stopwords)\n",
    "all_words = all_text.split()\n",
    "all_words = [word for word in all_words if word not in stopwords_english]\n",
    "overall_word_counts = Counter(all_words)\n",
    "# Get the 50 most common words across all sentiments\n",
    "most_common_overall = set([word for word, count in overall_word_counts.most_common(50)])\n",
    "\n",
    "\n",
    "# Word clouds per sentiment category, excluding overall most common words\n",
    "sentiments = df['sentiment'].unique()\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    sentiment_text = ' '.join(df[df['sentiment'] == sentiment]['cleaned_input'].dropna())\n",
    "    if sentiment_text:\n",
    "        # Remove overall most common words from sentiment-specific text\n",
    "        sentiment_words = sentiment_text.split()\n",
    "        sentiment_words_filtered = [word for word in sentiment_words if word not in most_common_overall and word not in stopwords_english]\n",
    "        filtered_sentiment_text = ' '.join(sentiment_words_filtered)\n",
    "\n",
    "        if filtered_sentiment_text:\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords_english).generate(filtered_sentiment_text)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Word Cloud for Sentiment: {sentiment} (excluding overall common words)')\n",
    "            plt.show()\n",
    "        else:\n",
    "             print(f\"No significant words remaining for sentiment: {sentiment} after filtering.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"No cleaned text available for sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "034a0d01"
   },
   "source": [
    "# Task - PREPROCESSING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3b6442b"
   },
   "source": [
    "## Pembersihan Teks Lanjutan untuk Kompatibilitas LLM\n",
    "\n",
    "Lakukan pembersihan teks lebih lanjut pada kolom 'cleaned_input' dengan menghapus URL, tag HTML, karakter khusus, dan menormalisasi spasi putih. Tampilkan beberapa contoh teks yang sudah dibersihkan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d120ae42",
    "outputId": "ff52271d-9ccd-47ed-abb0-55e0a81bc7a2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def advanced_text_cleaning(text):\n",
    "    if not isinstance(text, str): # Handle non-string inputs, if any\n",
    "        return text\n",
    "\n",
    "    # 1. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 2. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # 3. Remove special characters (keep letters, numbers, and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # 4. Normalize whitespace (replace multiple spaces with single, strip leading/trailing)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'cleaned_input' column\n",
    "df['further_cleaned_input'] = df['cleaned_input'].apply(advanced_text_cleaning)\n",
    "\n",
    "# Display the first few rows with the relevant columns to verify\n",
    "display(df[['input', 'cleaned_input', 'further_cleaned_input']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24a24d55"
   },
   "source": [
    "## Encoding Label Sentimen\n",
    "\n",
    "Ubah label sentimen kategorikal ('positive', 'negative', 'neutral') menjadi representasi numerik. Tampilkan pemetaan dan DataFrame yang diperbarui.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6abf6d09",
    "outputId": "7d29ab12-9055-4622-b1f0-aa2255c66788"
   },
   "outputs": [],
   "source": [
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "df['sentiment_encoded'] = df['sentiment'].map(sentiment_mapping)\n",
    "\n",
    "print(\"Sentiment Mapping:\")\n",
    "print(sentiment_mapping)\n",
    "\n",
    "print(\"\\nDataFrame with encoded sentiments:\")\n",
    "display(df[['sentiment', 'sentiment_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ddbfd2f"
   },
   "source": [
    "## Pembagian Data Training, Validation, dan Testing\n",
    "\n",
    "Bagi DataFrame menjadi set pelatihan (70%), validasi (15%), dan pengujian (15%) menggunakan `train_test_split` dengan stratifikasi untuk menjaga distribusi sentimen. Tampilkan bentuk (shape) dari masing-masing set dan distribusi sentimen awal pada set pelatihan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62049910",
    "outputId": "beca98e2-619b-42ea-8b9b-dff71459ba6b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split df into training (70%) and a temporary set (30%)\n",
    "df_train, df_temp, _, _ = train_test_split(df, df['sentiment_encoded'], test_size=0.3, random_state=42, stratify=df['sentiment_encoded'])\n",
    "\n",
    "# Split the temporary set into validation (15%) and test (15%)\n",
    "# test_size=0.5 because 0.5 * 30% = 15% of the original dataset\n",
    "df_val, df_test, _, _ = train_test_split(df_temp, df_temp['sentiment_encoded'], test_size=0.5, random_state=42, stratify=df_temp['sentiment_encoded'])\n",
    "\n",
    "print(\"Shape of training set:\", df_train.shape)\n",
    "print(\"Shape of validation set:\", df_val.shape)\n",
    "print(\"Shape of test set:\", df_test.shape)\n",
    "\n",
    "print(\"\\nSentiment distribution in training set:\")\n",
    "print(df_train['sentiment'].value_counts())\n",
    "print(\"\\nSentiment proportion in training set:\")\n",
    "print(df_train['sentiment'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the barplot before oversampling\n",
    "split_counts_before_oversampling = pd.DataFrame({\n",
    "  'Split': ['Training', 'Training', 'Training', 'Validation', 'Validation', 'Validation', 'Testing', 'Testing', 'Testing'],\n",
    "  'Sentiment': ['positive', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'negative'],\n",
    "  'Count': [\n",
    "    len(df_train[df_train['sentiment'] == 'positive']),\n",
    "    len(df_train[df_train['sentiment'] == 'neutral']),\n",
    "    len(df_train[df_train['sentiment'] == 'negative']),\n",
    "    len(df_val[df_val['sentiment'] == 'positive']),\n",
    "    len(df_val[df_val['sentiment'] == 'neutral']),\n",
    "    len(df_val[df_val['sentiment'] == 'negative']),\n",
    "    len(df_test[df_test['sentiment'] == 'positive']),\n",
    "    len(df_test[df_test['sentiment'] == 'neutral']),\n",
    "    len(df_test[df_test['sentiment'] == 'negative'])\n",
    "  ]\n",
    "})\n",
    "\n",
    "# Create the barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='Split', y='Count', hue='Sentiment', data=split_counts_before_oversampling, palette=sentiment_colors)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for container in ax.containers:\n",
    "  ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.title('Distribution of Data Across Training, Validation, and Testing Sets (Before Oversampling)')\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Before Oversampling:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTraining Set:\")\n",
    "print(df_train['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_train)}\")\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "print(df_val['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_val)}\")\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(df_test['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "276d059b"
   },
   "source": [
    "## Oversampling pada Set Pelatihan\n",
    "\n",
    "Lakukan oversampling pada set pelatihan (training set) menggunakan teknik duplikasi (resampling) untuk menyeimbangkan distribusi kelas sentimen. Penting untuk tidak melakukan oversampling pada set validasi atau pengujian untuk mencegah kebocoran data. Tampilkan distribusi sentimen dan bentuk dari set pelatihan setelah oversampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1954941",
    "outputId": "d08aaea6-789b-4864-dbeb-f4f33f63c33c"
   },
   "outputs": [],
   "source": [
    "# Identify the majority class count\n",
    "majority_class = df_train['sentiment'].value_counts().idxmax()\n",
    "majority_count = df_train['sentiment'].value_counts().max()\n",
    "\n",
    "df_train_oversampled = pd.DataFrame(columns=df_train.columns)\n",
    "\n",
    "# Oversample minority classes\n",
    "for sentiment_label in df_train['sentiment'].unique():\n",
    "    sentiment_df = df_train[df_train['sentiment'] == sentiment_label]\n",
    "    if len(sentiment_df) < majority_count:\n",
    "        # Duplicate samples until it matches the majority_count\n",
    "        oversampled_sentiment_df = sentiment_df.sample(majority_count, replace=True, random_state=42)\n",
    "        df_train_oversampled = pd.concat([df_train_oversampled, oversampled_sentiment_df])\n",
    "    else:\n",
    "        df_train_oversampled = pd.concat([df_train_oversampled, sentiment_df])\n",
    "\n",
    "print(\"Shape of oversampled training set:\", df_train_oversampled.shape)\n",
    "print(\"\\nSentiment distribution in oversampled training set:\")\n",
    "print(df_train_oversampled['sentiment'].value_counts())\n",
    "print(\"\\nSentiment proportion in oversampled training set:\")\n",
    "print(df_train_oversampled['sentiment'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the barplot after oversampling\n",
    "split_counts_after_oversampling = pd.DataFrame({\n",
    "  'Split': ['Training', 'Training', 'Training', 'Validation', 'Validation', 'Validation', 'Testing', 'Testing', 'Testing'],\n",
    "  'Sentiment': ['positive', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'negative'],\n",
    "  'Count': [\n",
    "    len(df_train_oversampled[df_train_oversampled['sentiment'] == 'positive']),\n",
    "    len(df_train_oversampled[df_train_oversampled['sentiment'] == 'neutral']),\n",
    "    len(df_train_oversampled[df_train_oversampled['sentiment'] == 'negative']),\n",
    "    len(df_val[df_val['sentiment'] == 'positive']),\n",
    "    len(df_val[df_val['sentiment'] == 'neutral']),\n",
    "    len(df_val[df_val['sentiment'] == 'negative']),\n",
    "    len(df_test[df_test['sentiment'] == 'positive']),\n",
    "    len(df_test[df_test['sentiment'] == 'neutral']),\n",
    "    len(df_test[df_test['sentiment'] == 'negative'])\n",
    "  ]\n",
    "})\n",
    "\n",
    "# Create the barplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x='Split', y='Count', hue='Sentiment', data=split_counts_after_oversampling, palette=sentiment_colors)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for container in ax.containers:\n",
    "  ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.title('Distribution of Data Across Training, Validation, and Testing Sets (After Oversampling)')\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary After Oversampling:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTraining Set:\")\n",
    "print(df_train_oversampled['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_train_oversampled)}\")\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "print(df_val['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_val)}\")\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(df_test['sentiment'].value_counts().sort_index())\n",
    "print(f\"Total: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the barplot\n",
    "split_counts = pd.DataFrame({\n",
    "  'Split': ['Training', 'Validation', 'Testing'],\n",
    "  'Count': [len(df_train_oversampled), len(df_val), len(df_test)]\n",
    "})\n",
    "\n",
    "# Create the barplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Split', y='Count', data=split_counts, palette='viridis')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for container in ax.containers:\n",
    "  ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.title('Distribution of Data Across Training, Validation, and Testing Sets')\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Display sentiment distribution for each split\n",
    "print(\"Sentiment Distribution in Training Set:\")\n",
    "print(df_train_oversampled['sentiment'].value_counts())\n",
    "print(f\"\\nTotal Training Samples: {len(df_train_oversampled)}\")\n",
    "\n",
    "print(\"\\nSentiment Distribution in Validation Set:\")\n",
    "print(df_val['sentiment'].value_counts())\n",
    "print(f\"\\nTotal Validation Samples: {len(df_val)}\")\n",
    "\n",
    "print(\"\\nSentiment Distribution in Testing Set:\")\n",
    "print(df_test['sentiment'].value_counts())\n",
    "print(f\"\\nTotal Testing Samples: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "616bd81d"
   },
   "source": [
    "# Task - TRAINING MODEL\n",
    "**Tokenisasi dan Persiapan Data untuk Model BERT**: Lakukan tokenisasi pada kolom 'further_cleaned_input' menggunakan tokenizer BERT. Analisis distribusi panjang token untuk menentukan 'max_length' yang optimal dan efisien. Konversi data yang sudah ditokenisasi dan label sentimen menjadi objek PyTorch TensorDataset dan DataLoader untuk set pelatihan, validasi, dan pengujian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e816e7d4"
   },
   "source": [
    "## Tokenisasi dan Persiapan Data untuk Model BERT\n",
    "\n",
    "Lakukan tokenisasi pada kolom 'further_cleaned_input' menggunakan tokenizer BERT. Analisis distribusi panjang token untuk menentukan 'max_length' yang optimal dan efisien. Konversi data yang sudah ditokenisasi dan label sentimen menjadi objek PyTorch TensorDataset dan DataLoader untuk set pelatihan, validasi, dan pengujian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287,
     "referenced_widgets": [
      "fe37277bad4748bfa93aa248152ddb9f",
      "dab690b10ef4454ba9cb4201e1409a32",
      "4b4d4e00fc8f4d428105d8e9a3abd1c4",
      "ee040eecfb464bd0bf4be0ad0cd2b3e0",
      "f6742c27d55e4417b1bf62605d8d6cd7",
      "f200258c028b48309d6286ee1e6fe80f",
      "7da2fc662a4a407d8ab0cfbc0f207669",
      "98fd717f467e4ec6a44988cff2ca784f",
      "61c06fbdab4543daa7c0893a78591b86",
      "ebf33c3309e04b0f8b43bf3fde53622e",
      "2de3d41da29b45dab61029f95753219c",
      "d9a04c3618204d4bba8f52a2eebd1b47",
      "1487c65c80124896afd2d77f8e68375f",
      "e2fde30511994f91a5735b01e808883a",
      "9426f242b6464523b2fad9c49c37047a",
      "92df94c9e99b442b90f5d9131f87f8e0",
      "2677c630f6074f739928b9f7b380b3b7",
      "d6cf6867a1404b65a740261cc5745814",
      "afeef0a6fc6b454e851909940367ef4c",
      "abe2a2c350aa4fa3919e0d988b40a441",
      "46597ced4cc645aa9ccb68427586aadd",
      "ed5384e2e45c47ca87855239223d6fed",
      "c4b7de54ffcb45668e87f358caebc693",
      "74070750f947424ba5f9155e013f6653",
      "19db4d3251364fc0a5ed94c3ffe6aa92",
      "e2cdc53cd6cc42648b86ccb3f94275de",
      "f08aa34553954875b51a2559b1e1e85c",
      "1c2e142f4b694b0f931514454d0002e4",
      "d71012fd895e4b16a610f6a3839d7788",
      "e4a8879929c24637baa7263af73418f6",
      "773580448d6146549abe576c0c967679",
      "546e41122ac147648362cde1e420147e",
      "5a76f6c66db34b0faa5cc73dc4ded128",
      "9c974c2d3dfb406fb4f22c36cfe99b17",
      "5c70985106834e5ab50ced6b6f8386d9",
      "f52d0e7af9fd42dcb7b31940583e6a3f",
      "0d334132b40e43398729afa8f023617c",
      "73e764d9da814844ab3c7d60e44868eb",
      "844c16b3c1094c37a056fbbcb47d2dca",
      "860e91df43ec4a109af8b51ee288bb0f",
      "4d786dbfe0fa4de2bb7f92bedd9b3c60",
      "7f83e9971ba5481eb46bb17eb58474c6",
      "f1d5e37efa014ec1a51300cf0f7c4e8a",
      "07ed271aaf90491fbf5dce603a4ac3fd"
     ]
    },
    "id": "04f5b271",
    "outputId": "63739e82-33fe-4dbf-d6ea-23be0a51a927"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"BERT Tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "dc8fa313",
    "outputId": "bdcaf054-39dc-4f58-af92-451028933e72"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Calculate token lengths for the oversampled training data\n",
    "# Explicitly truncate to the model's maximum length (e.g., 512 for bert-base-uncased)\n",
    "# when calculating lengths for distribution analysis to avoid warnings about exceeding model_max_length\n",
    "# and to inform our choice of MAX_LENGTH based on what the model can actually handle.\n",
    "token_lengths = [len(tokenizer.encode(str(text), add_special_tokens=True, truncation=True, max_length=tokenizer.model_max_length)) for text in df_train_oversampled['further_cleaned_input']]\n",
    "\n",
    "# Plot the distribution of token lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(token_lengths, bins=50, kde=True)\n",
    "plt.title('Distribution of Token Lengths in Oversampled Training Data (Truncated at 512)')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Report some statistics\n",
    "print(f\"Max token length (after truncation at 512): {max(token_lengths)}\")\n",
    "print(f\"Average token length: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"90th percentile token length: {np.percentile(token_lengths, 90):.2f}\")\n",
    "print(f\"95th percentile token length: {np.percentile(token_lengths, 95):.2f}\")\n",
    "print(f\"99th percentile token length: {np.percentile(token_lengths, 99):.2f}\")\n",
    "\n",
    "# Based on the distribution and common BERT usage, choose an optimal max_length\n",
    "# We aim to cover most data efficiently, typically less than or equal to 512.\n",
    "MAX_LENGTH = int(np.percentile(token_lengths, 95)) # The previous output suggests 95th percentile is 228.55, 99th is 425.00\n",
    "                # Keeping 229 as a good balance for efficiency, as it captures the majority of short texts.\n",
    "\n",
    "print(f\"\\nChosen MAX_LENGTH for tokenization: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff41488d",
    "outputId": "4125a53a-7fcf-455b-d7f5-5fbc8cfd7c85"
   },
   "outputs": [],
   "source": [
    "def tokenize_data(texts, tokenizer, max_length):\n",
    "    return tokenizer(list(texts), padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "# Apply tokenization to the oversampled training, validation, and test sets\n",
    "X_train_tokenized = tokenize_data(df_train_oversampled['further_cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "X_val_tokenized = tokenize_data(df_val['further_cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "X_test_tokenized = tokenize_data(df_test['further_cleaned_input'], tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(\"Tokenization applied to training, validation, and test sets.\")\n",
    "print(f\"Training set tokenized shape (input_ids): {X_train_tokenized['input_ids'].shape}\")\n",
    "print(f\"Validation set tokenized shape (input_ids): {X_val_tokenized['input_ids'].shape}\")\n",
    "print(f\"Test set tokenized shape (input_ids): {X_test_tokenized['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08551594",
    "outputId": "6c1e5917-84cb-4849-cbbe-ce94f6543957"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert tokenized inputs to PyTorch tensors\n",
    "input_ids_train = X_train_tokenized['input_ids']\n",
    "attention_mask_train = X_train_tokenized['attention_mask']\n",
    "token_type_ids_train = X_train_tokenized['token_type_ids']\n",
    "labels_train = torch.tensor(df_train_oversampled['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "input_ids_val = X_val_tokenized['input_ids']\n",
    "attention_mask_val = X_val_tokenized['attention_mask']\n",
    "token_type_ids_val = X_val_tokenized['token_type_ids']\n",
    "labels_val = torch.tensor(df_val['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "input_ids_test = X_test_tokenized['input_ids']\n",
    "attention_mask_test = X_test_tokenized['attention_mask']\n",
    "token_type_ids_test = X_test_tokenized['token_type_ids']\n",
    "labels_test = torch.tensor(df_test['sentiment_encoded'].values.astype(int))\n",
    "\n",
    "print(\"Tokenized data and sentiment labels converted to PyTorch tensors.\")\n",
    "print(f\"Labels train shape: {labels_train.shape}\")\n",
    "print(f\"Labels val shape: {labels_val.shape}\")\n",
    "print(f\"Labels test shape: {labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a5a95bd",
    "outputId": "679b57a8-b97a-42ed-9258-ee3611a864e3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create TensorDataset for training, validation, and test sets\n",
    "train_dataset = TensorDataset(input_ids_train, attention_mask_train, token_type_ids_train, labels_train)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_mask_val, token_type_ids_val, labels_val)\n",
    "test_dataset = TensorDataset(input_ids_test, attention_mask_test, token_type_ids_test, labels_test)\n",
    "\n",
    "print(\"TensorDatasets created successfully.\")\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abef8bb5",
    "outputId": "ea7dd107-1b21-42d7-d986-95d101c15e52"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully.\")\n",
    "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
    "print(f\"Number of batches in validation DataLoader: {len(val_dataloader)}\")\n",
    "print(f\"Number of batches in test DataLoader: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a62f26e4"
   },
   "source": [
    "## Pemuatan Model BERT dan Konfigurasi Lingkungan Pelatihan\n",
    "\n",
    "Muat model pre-trained `BertForSequenceClassification` dari Hugging Face Transformers. Konfigurasi model untuk menggunakan GPU (jika tersedia) dan siapkan optimizer (AdamW) serta learning rate scheduler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "049a2dcc71424e4998f45802d29470dc",
      "e43513bfbdd64c9fa6c3e60b68949338",
      "63f254fa2ffc45818d344d26182a75af",
      "e20188e245f8484691761968306df634",
      "4cd7b5940bc54cd792c930741e4b5262",
      "de212c1dc8a849a689dff662841906aa",
      "677c9ab081534a858624749308594320",
      "3ab55ed230df4511936b7407bc50d81b",
      "3696f72601ac4ec68cf5a10fc7598d5a",
      "3247d0170e59430fbd2746c71648f053",
      "0b5003d29360482dbbcaf8e410a9fc50"
     ]
    },
    "id": "0462d3db",
    "outputId": "31a3ffd1-da53-4d58-d3f9-0d9ff6bd99b9"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Set device (GPU if available)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "num_labels = 3\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = num_labels,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"BERT model loaded and moved to device successfully.\")\n",
    "\n",
    "# Initialize AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "print(\"AdamW optimizer initialized.\")\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "EPOCHS = 5\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "print(f\"Learning rate scheduler initialized for {total_steps} training steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d85d157",
    "outputId": "3b47974e-a8fe-4983-c037-101fc6a57e2e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Function to format elapsed time\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# Set the seed for reproducible results\n",
    "seed_val = 42\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss and accuracy over all epochs\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    print(f'\\n======== Epoch {epoch_i + 1} / {EPOCHS} ========')\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train() # Set the model to training mode\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip the norm of the gradients to 1.0\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(f'  Average training loss: {avg_train_loss:.2f}')\n",
    "    print(f'  Training epoch took: {format_time(time.time() - t0)}')\n",
    "\n",
    "    print('\\nRunning Validation...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Lists to store predictions and true labels for confusion matrix\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels\n",
    "            )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        # Store predictions and labels\n",
    "        val_preds.extend(np.argmax(logits, axis=1))\n",
    "        val_labels.extend(label_ids)\n",
    "\n",
    "    print(f'  Validation Loss: {eval_loss / nb_eval_steps:.2f}')\n",
    "    print(f'  Validation Accuracy: {eval_accuracy / nb_eval_steps:.2f}')\n",
    "    print(f'  Validation took: {format_time(time.time() - t0)}')\n",
    "\n",
    "    # Display Confusion Matrix\n",
    "    cm = confusion_matrix(val_labels, val_preds)\n",
    "    print(f\"\\n  Confusion Matrix (Epoch {epoch_i + 1}):\")\n",
    "    print(cm)\n",
    "\n",
    "print('\\nTraining complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpan Model ke Local Storage\n",
    "\n",
    "Simpan model yang telah dilatih dan tokenizer ke direktori lokal agar dapat digunakan kembali nanti tanpa perlu melatih ulang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(f\"Saving model to {output_dir}\")\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"Model and tokenizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muat Model dari Local Storage\n",
    "\n",
    "Muat kembali model dan tokenizer yang telah disimpan untuk pengujian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "print(f\"Loading model from {output_dir}\")\n",
    "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi Final pada Validation Set\n",
    "\n",
    "Evaluasi model pada validation set setelah training selesai untuk memastikan model tidak overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Final evaluation on the validation dataset\n",
    "print(\"Final Evaluation on Validation Dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "val_loss = 0\n",
    "val_accuracy = 0\n",
    "nb_val_steps = 0\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "val_preds_final = []\n",
    "val_labels_final = []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(\n",
    "      b_input_ids,\n",
    "      token_type_ids=None,\n",
    "      attention_mask=b_input_mask,\n",
    "      labels=b_labels\n",
    "    )\n",
    "\n",
    "  logits = outputs.logits\n",
    "  loss = outputs.loss\n",
    "  val_loss += loss.item()\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  tmp_val_accuracy = flat_accuracy(logits, label_ids)\n",
    "  val_accuracy += tmp_val_accuracy\n",
    "  nb_val_steps += 1\n",
    "\n",
    "  # Store predictions and labels\n",
    "  val_preds_final.extend(np.argmax(logits, axis=1))\n",
    "  val_labels_final.extend(label_ids)\n",
    "\n",
    "avg_val_loss = val_loss / nb_val_steps\n",
    "avg_val_accuracy = val_accuracy / nb_val_steps\n",
    "\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "print(f\"Validation evaluation took: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Display Confusion Matrix for validation set\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Confusion Matrix on Validation Set:\")\n",
    "print(\"=\"*50)\n",
    "cm_val = confusion_matrix(val_labels_final, val_preds_final)\n",
    "print(cm_val)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Greens',\n",
    "      xticklabels=['negative', 'neutral', 'positive'],\n",
    "      yticklabels=['negative', 'neutral', 'positive'])\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Classification Report (Validation Set):\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(val_labels_final, val_preds_final,\n",
    "              target_names=['negative', 'neutral', 'positive']))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Overfitting Check:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Loss (Final Epoch): {loss_values[-1]:.4f}\")\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Difference: {abs(avg_val_loss - loss_values[-1]):.4f}\")\n",
    "if avg_val_loss > loss_values[-1] * 1.2:\n",
    "    print(\" WARNING: Model might be overfitting! Validation loss is significantly higher than training loss.\")\n",
    "elif avg_val_loss <= loss_values[-1] * 1.1:\n",
    "    print(\" Model is generalizing well. No significant overfitting detected.\")\n",
    "else:\n",
    "    print(\" CAUTION: There is some difference between training and validation loss. Monitor closely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Testing the model on the test dataset\n",
    "print(\"Testing the model on the test dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "nb_test_steps = 0\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(\n",
    "      b_input_ids,\n",
    "      token_type_ids=None,\n",
    "      attention_mask=b_input_mask,\n",
    "      labels=b_labels\n",
    "    )\n",
    "\n",
    "  logits = outputs.logits\n",
    "  loss = outputs.loss\n",
    "  test_loss += loss.item()\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
    "  test_accuracy += tmp_test_accuracy\n",
    "  nb_test_steps += 1\n",
    "\n",
    "  # Store predictions and labels\n",
    "  test_preds.extend(np.argmax(logits, axis=1))\n",
    "  test_labels_list.extend(label_ids)\n",
    "\n",
    "avg_test_loss = test_loss / nb_test_steps\n",
    "avg_test_accuracy = test_accuracy / nb_test_steps\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {avg_test_accuracy:.4f}\")\n",
    "print(f\"Testing took: {format_time(time.time() - t0)}\")\n",
    "\n",
    "# Display Confusion Matrix for test set\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Confusion Matrix on Test Set:\")\n",
    "print(\"=\"*50)\n",
    "cm_test = confusion_matrix(test_labels_list, test_preds)\n",
    "print(cm_test)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n",
    "      xticklabels=['negative', 'neutral', 'positive'],\n",
    "      yticklabels=['negative', 'neutral', 'positive'])\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(test_labels_list, test_preds,\n",
    "              target_names=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "from google.colab import auth\n",
    "from google.auth import default\n",
    "from googleapiclient.discovery import build\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# --- 1. Identify User ---\n",
    "try:\n",
    "    print(\"Retrieving user information...\")\n",
    "    auth.authenticate_user()\n",
    "    creds, _ = default()\n",
    "    oauth_service = build('oauth2', 'v2', credentials=creds)\n",
    "    user_info = oauth_service.userinfo().get().execute()\n",
    "    current_email = user_info.get('email')\n",
    "    print(f\" Logged in as: {current_email}\")\n",
    "except Exception as e:\n",
    "    print(f\" Could not retrieve email address automatically. (Error: {e})\")\n",
    "\n",
    "# --- 2. Save to Google Drive ---\n",
    "# Check if Drive is already mounted to avoid \"Mountpoint must not already contain files\" error\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\" Google Drive is already mounted.\")\n",
    "else:\n",
    "    print(\"Mounting Google Drive...\")\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Define source (Colab VM) and destination (Google Drive)\n",
    "source_dir = './model_save/'\n",
    "# Saving to 'PSD_Model_Save' folder in your Drive\n",
    "destination_dir = '/content/drive/MyDrive/PSD_Model_Save/'\n",
    "\n",
    "# Create destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "    print(f\"Created directory: {destination_dir}\")\n",
    "\n",
    "# Copy the model files\n",
    "print(f\"Copying files from {source_dir} to {destination_dir}...\")\n",
    "# Using system command for recursive copy\n",
    "exit_code = os.system(f'cp -r \"{source_dir}\"* \"{destination_dir}\"')\n",
    "if exit_code == 0:\n",
    "    print(f\" Model successfully saved to Google Drive at: {destination_dir}\")\n",
    "    if 'current_email' in locals():\n",
    "        print(f\"   (Account: {current_email})\")\n",
    "else:\n",
    "    print(\" Error copying files to Google Drive.\")\n",
    "\n",
    "# --- 3. Download to Local ---\n",
    "print(\"\\nPreparing file for local download...\")\n",
    "zip_base_name = 'bert_model_save'\n",
    "zip_filename = zip_base_name + '.zip'\n",
    "\n",
    "# Zip the directory\n",
    "shutil.make_archive(zip_base_name, 'zip', source_dir)\n",
    "print(f\"Created zip file: {zip_filename}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Attempting to download {zip_filename}...\")\n",
    "    files.download(zip_filename)\n",
    "    print(\" Download command sent.\")\n",
    "except Exception as e:\n",
    "    print(f\" Could not trigger direct download (common in VS Code remote kernels).\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\" You can download the file '{zip_filename}' manually from the file explorer on the left,\")\n",
    "    print(f\"   or access the copy we just saved in your Google Drive folder: {destination_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9471778b"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
